{"cells":[{"cell_type":"markdown","metadata":{"id":"DVeelyV4HcWg"},"source":["# Homework 5: Bayesian Classifiers\n","\n","Follow the instructions in the template, score will be given uppon it."]},{"cell_type":"markdown","metadata":{"id":"mwEcTO2FHcWq"},"source":["### Import libraries\n","You are allowed to use these libraries only."]},{"cell_type":"code","execution_count":1,"metadata":{"ExecuteTime":{"end_time":"2021-05-08T15:38:19.168746Z","start_time":"2021-05-08T15:38:17.638784Z"},"id":"8uluoR5zHcWs"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from matplotlib import pyplot as plt"]},{"cell_type":"markdown","metadata":{"id":"5MfnYRmoHcWu"},"source":["## Part 1 - Bernoulli Naive Bayes"]},{"cell_type":"code","execution_count":2,"metadata":{"ExecuteTime":{"end_time":"2021-05-08T15:38:19.177980Z","start_time":"2021-05-08T15:38:19.170862Z"},"id":"-dNbJeDdHcWv"},"outputs":[],"source":["data = pd.read_csv(\"train_NB.csv\")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>X1</th>\n","      <th>X2</th>\n","      <th>X3</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   X1  X2  X3  Label\n","0   1   1   1      1\n","1   1   0   0      0\n","2   0   0   1      1\n","3   1   0   0      0\n","4   0   0   1      1\n","5   0   1   1      1\n","6   1   1   1      0\n","7   1   1   0      0\n","8   0   1   1      1"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["data"]},{"cell_type":"markdown","metadata":{"id":"opaZXxBHHcWw"},"source":["The data, the X and the y. "]},{"cell_type":"code","execution_count":4,"metadata":{"ExecuteTime":{"end_time":"2021-05-08T15:41:23.264585Z","start_time":"2021-05-08T15:41:23.260475Z"},"id":"Ez4w4ecGHcWx"},"outputs":[],"source":["X = data.drop(columns='Label').values\n","y = data['Label'].values\n"]},{"cell_type":"markdown","metadata":{"id":"B4LguoguHcWy"},"source":["Here you should write down your code. It's ok if the code is suitable for just 2 classes."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":16,"metadata":{"ExecuteTime":{"end_time":"2021-05-08T15:41:24.548785Z","start_time":"2021-05-08T15:41:24.542854Z"},"id":"wfVOLmY0HcWz"},"outputs":[],"source":["class BernoulliNaiveBayes:\n","    \n","    def __init__(self):  \n","        pass\n","    \n","    def fit(self, X, y):\n","        # X and y are numpy arrays.\n","        # Use numpy (or pandas) the find the priors, P(y=0) and P(y=1)\n","        # find P(X=1|y=0) and P(X=1|y=1) for each feature.\n","        # The .fit method can be written in 3 lines of code. \n","        prior = lambda yi: y[y==yi].shape[0] / y.shape[0]\n","        self.priors = np.array([prior(y_class) for y_class in sorted(np.unique(y))])\n","        self.X = X\n","        self.y = y\n","        \n","        \n","    def predict_proba(self, X) -> np.array:      \n","        # Given a new sample X, you should return a probability vector with 2 elements.\n","        # The probability of class 0, and the probability of class 1.\n","        # Given an n by p matrix, you should return an n by 2 matrix.\n","        # The .predict_proba method can be written in 3 lines of code. (you may also use more)\n","        result = []        \n","        X_train1 = self.X\n","        if type(X_train1) == pd.DataFrame:\n","            X_train1 = X_train1.values\n","        likelihood_mat = self.get_likelihood()\n","        \n","        p_xs_1 = X_train1.sum(axis=0) / X_train1.shape[0]\n","        \n","        result = []\n","        \n","        for y_class in (0,1):\n","            prior = self.priors[y_class]\n","            for i in range(X.shape[0]):\n","                row = []\n","                p_x = 1\n","                p_l = 1\n","                for j in range(X.shape[1]):\n","                    value = X_train1[i,j]\n","                    p_xj = p_xs_1[j] if value == 1 else (1 -  p_xs_1[j])\n","                    p_x *= p_xj\n","\n","                    p_lj = likelihood_mat[y_class, j] if value == 1 else (1 - likelihood_mat[y_class, j])\n","                    p_l *= p_lj\n","                    row.append((prior*p_l) / p_x)\n","                result.append(row)\n","        return np.array(result).T\n","            \n","\n","        \n","\n","    def predict(self, X) -> np.array:\n","        # Given a new sample X, you should return the predicted label, which is the one with the highest probability.\n","        # You may use previous methods\n","        #TODO: your solution\n","        return np.max(self.predict_proba(X), axis=0)\n","\n","    def get_likelihood(self) -> np.array:\n","        # Returns the likelihood for each x value, given the y value p(x|y).\n","        # Should return a matrix with shape: (#classes, #features)\n","        # for that matrix X[i,j] = p(X_j=1|y=i)\n","        X = self.X\n","        y = self.y\n","        likelihood_calc = lambda yi: (X[y==yi].sum(axis=0) / y[y==yi].shape[0])\n","        return np.array([likelihood_calc(y_class) for y_class in sorted(np.unique(y))])\n","\n"]},{"cell_type":"markdown","metadata":{"id":"k6DaaEEqHcW3"},"source":["In order to make sure you have done it right, check the probabilities for the samples [[1,0,1], [1,1,1], [0,1,1]]. <br>\n"]},{"cell_type":"code","execution_count":17,"metadata":{"ExecuteTime":{"end_time":"2021-05-08T15:41:25.536108Z","start_time":"2021-05-08T15:41:25.531750Z"},"id":"q6tS4xUpHcW5","outputId":"0e0ab3b4-7625-4994-a880-a667043a6b5a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[0.8   0.8   0.    0.2   0.2   1.   ]\n"," [0.72  0.9   0.    0.216 0.18  0.9  ]\n"," [0.27  2.025 0.    0.324 0.    1.35 ]]\n","[0.8   2.025 0.    0.324 0.2   1.35 ]\n"]}],"source":["clf = BernoulliNaiveBayes() #It is the class you just wrote down.\n","\n","test = np.array([\n","    [1,0,1],\n","    [1,1,1],\n","    [0,1,1]]) #The test sample.\n","\n","clf.fit(X,y)\n","\n","print (clf.predict_proba(test))\n","\n","#expected answer:\n","#[[ 0.55555556  0.44444444]\n","# [ 0.45454545  0.54545455]\n","# [ 0.          1.        ]]\n","\n","print(clf.predict(test))\n","\n","# expected answer:\n","# [0,1,1]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["array([[1, 0, 1],\n","       [1, 1, 1],\n","       [0, 1, 1]])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["test"]},{"cell_type":"markdown","metadata":{"id":"Krk44fCHHcW9"},"source":["# Part 2 - Predicting  gender from name"]},{"cell_type":"markdown","metadata":{"id":"Ig3JXYpQHcW_"},"source":["### read data"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-05-08T15:44:11.306574Z","start_time":"2021-05-08T15:44:11.290939Z"},"id":"SUFxfwg1HcXA"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>name</th>\n","      <th>is_female</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Dorian</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Loella</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Minda</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Lou</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Michaeline</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>7939</th>\n","      <td>Reza</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7940</th>\n","      <td>Samuele</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>7941</th>\n","      <td>Ralina</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7942</th>\n","      <td>Aloisia</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>7943</th>\n","      <td>Natka</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>7944 rows × 2 columns</p>\n","</div>"],"text/plain":["            name  is_female\n","0         Dorian          1\n","1         Loella          1\n","2          Minda          1\n","3            Lou          1\n","4     Michaeline          1\n","...          ...        ...\n","7939        Reza          0\n","7940     Samuele          0\n","7941      Ralina          1\n","7942     Aloisia          1\n","7943       Natka          1\n","\n","[7944 rows x 2 columns]"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["df = pd.read_csv(\"names.csv\", index_col=0)\n","y = df.is_female\n","df"]},{"cell_type":"markdown","metadata":{"id":"h3JwJJo4HcXA"},"source":["### generate features"]},{"cell_type":"markdown","metadata":{"id":"1jAoYMYWHcXB"},"source":["In this part, you shall perform a task from the domain of Natural Language Processing (NLP).\n","You shall predict whether a name belongs to a male or a female. For simplicity, we shall do this only based on the last letter of the name.\n","In NLP many times we need to make up features using expert knowledge to be able to classify words. <br>\n","In the following cell you are asked to:\n","1. Extract the last letter of every name\n","2. Make a **Numpy array** `X` of dummy varialbes (one hot encoding) from the last letter feature.<br>\n","   (use pd.get_dummies)"]},{"cell_type":"code","execution_count":null,"metadata":{"ExecuteTime":{"end_time":"2021-05-08T15:38:23.592091Z","start_time":"2021-05-08T15:38:23.585171Z"},"id":"fcEhXaAnHcXB"},"outputs":[],"source":["last_letter = pd.Series([name[-1] for name in df.name], index=df.index)\n","\n","#TODO: Make binary data \n","X = pd.get_dummies(last_letter)\n"]},{"cell_type":"markdown","metadata":{"id":"TUGpqlHCHcXC"},"source":["### train and predict"]},{"cell_type":"markdown","metadata":{"id":"gy5XtxfzHcXD"},"source":["Now that we have a binary data we can use the `BernoulliNaiveBayes` class you wrote to classify the names. <br>\n","Run the cell below to see the results, and answer the question below.\n","1. we plot 2 plots of the most common male/female letters ($P(X|y)$)\n","2. we plot the predictions ($P(y|X)$) for every letter"]},{"cell_type":"code","execution_count":18,"metadata":{"ExecuteTime":{"end_time":"2021-05-08T15:38:50.567665Z","start_time":"2021-05-08T15:38:50.192075Z"},"id":"M2YGbf8DHcXE","outputId":"12486b66-efcf-4d60-d39c-62cc247fb789","scrolled":false},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\itayz\\AppData\\Local\\Temp\\ipykernel_12420\\2169484599.py:5: DeprecationWarning: elementwise comparison failed; this will raise an error in the future.\n","  acc = (preds == y_test).mean()\n"]},{"ename":"AttributeError","evalue":"'bool' object has no attribute 'mean'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[1;32mc:\\Users\\itayz\\OneDrive\\לימודים\\למידת מכונה\\ML\\exercises\\HW5-205475593.ipynb Cell 23'\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/itayz/OneDrive/%D7%9C%D7%99%D7%9E%D7%95%D7%93%D7%99%D7%9D/%D7%9C%D7%9E%D7%99%D7%93%D7%AA%20%D7%9E%D7%9B%D7%95%D7%A0%D7%94/ML/exercises/HW5-205475593.ipynb#ch0000022?line=2'>3</a>\u001b[0m clf\u001b[39m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/itayz/OneDrive/%D7%9C%D7%99%D7%9E%D7%95%D7%93%D7%99%D7%9D/%D7%9C%D7%9E%D7%99%D7%93%D7%AA%20%D7%9E%D7%9B%D7%95%D7%A0%D7%94/ML/exercises/HW5-205475593.ipynb#ch0000022?line=3'>4</a>\u001b[0m preds \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/itayz/OneDrive/%D7%9C%D7%99%D7%9E%D7%95%D7%93%D7%99%D7%9D/%D7%9C%D7%9E%D7%99%D7%93%D7%AA%20%D7%9E%D7%9B%D7%95%D7%A0%D7%94/ML/exercises/HW5-205475593.ipynb#ch0000022?line=4'>5</a>\u001b[0m acc \u001b[39m=\u001b[39m (preds \u001b[39m==\u001b[39;49m y_test)\u001b[39m.\u001b[39;49mmean()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/itayz/OneDrive/%D7%9C%D7%99%D7%9E%D7%95%D7%93%D7%99%D7%9D/%D7%9C%D7%9E%D7%99%D7%93%D7%AA%20%D7%9E%D7%9B%D7%95%D7%A0%D7%94/ML/exercises/HW5-205475593.ipynb#ch0000022?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39maccuracy: \u001b[39m\u001b[39m{\u001b[39;00m(acc\u001b[39m*\u001b[39m\u001b[39m100\u001b[39m)\u001b[39m:\u001b[39;00m\u001b[39m.0f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/itayz/OneDrive/%D7%9C%D7%99%D7%9E%D7%95%D7%93%D7%99%D7%9D/%D7%9C%D7%9E%D7%99%D7%93%D7%AA%20%D7%9E%D7%9B%D7%95%D7%A0%D7%94/ML/exercises/HW5-205475593.ipynb#ch0000022?line=8'>9</a>\u001b[0m letters \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mb\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mc\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39md\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39me\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mg\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mh\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mi\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mj\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mk\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39ml\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mm\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mn\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/itayz/OneDrive/%D7%9C%D7%99%D7%9E%D7%95%D7%93%D7%99%D7%9D/%D7%9C%D7%9E%D7%99%D7%93%D7%AA%20%D7%9E%D7%9B%D7%95%D7%A0%D7%94/ML/exercises/HW5-205475593.ipynb#ch0000022?line=9'>10</a>\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mo\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mp\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mr\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39ms\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mu\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mv\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mz\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m# no name ending in `q`\u001b[39;00m\n","\u001b[1;31mAttributeError\u001b[0m: 'bool' object has no attribute 'mean'"]}],"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=6)\n","clf = BernoulliNaiveBayes() #It is the class you just wrote.\n","clf.fit(X_train, y_train)\n","preds = clf.predict(X_test)\n","acc = (preds == y_test).mean()\n","print(f\"accuracy: {(acc*100):.0f}%\")\n","\n","\n","letters = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n',\n","           'o', 'p', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'] # no name ending in `q`\n","\n","\n","#using likelihood method\n","likelihood_matrix = clf.get_likelihood()\n","p1 = likelihood_matrix[1]\n","p0 = likelihood_matrix[0]\n","# most indicating letter for each gender\n","female = pd.Series(p1, index=letters).sort_values(ascending=False).head(10)\n","male = pd.Series(p0, index=letters).sort_values(ascending=False).head(10)\n","\n","# plot results\n","plt.bar(female.index, female*100, color='firebrick')\n","plt.ylabel(\"% of females\")\n","plt.xlabel(\"last letter in name\")\n","plt.title(\"top 10 last letters for females\")\n","plt.ylim(0,40)\n","plt.show()\n","\n","plt.bar(male.index, male*100, color='mediumblue')\n","plt.ylabel(\"% of males\")\n","plt.ylim(0,40)\n","plt.xlabel(\"last letter in name\")\n","plt.title(\"top 10 last letters for males\")\n","plt.show()\n","\n","is_letter_female = clf.predict_proba(np.eye(25))[:, 1]\n","is_letter_female = pd.DataFrame(is_letter_female, index = letters, columns=['female_proba'])\n","is_letter_female = is_letter_female.sort_values('female_proba', ascending=False)\n","is_letter_female.style.background_gradient(cmap='coolwarm')"]},{"cell_type":"markdown","metadata":{"id":"LXESgrgSHcXG"},"source":["### question\n","explain how come the letter *i* has higher probability to be feminine than *y* even though it is less popular for women?"]},{"cell_type":"markdown","metadata":{"id":"0_dYhCUVHcXH"},"source":["**Answer:** <br>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0.09281914893617021\n","0.0186533212010919\n"]}],"source":["all_male = pd.Series(p0, index=letters).sort_values(ascending=False)\n","print(female.y)\n","print(all_male.i)\n"]},{"cell_type":"markdown","metadata":{},"source":["it is probebly because the letter `i` is in the top ten of `female`, but not in the top ten of `male`. unlike `y` which is popular in both groups.\n","\n","in fact `i` is almost ten times more popular with `female` compared to `male`.  \n","this makes `i` stronger in distinguishing between `male` and `female`."]}],"metadata":{"anaconda-cloud":{},"colab":{"name":"HW5 - Bayes - Solution.ipynb","provenance":[]},"interpreter":{"hash":"5bf76fd3945b4107cbfc10739b6970debd65a21d2ff65ed3f2e4d2ed64c8cd92"},"kernelspec":{"display_name":"Python 3.10.1 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.1"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":0}
